#!/usr/bin/env python3
"""
æ–‡æ¡£è®­ç»ƒé›†æˆå™¨ - å¤ç”¨ç°æœ‰è®­ç»ƒæ¡†æ¶
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))


def train_document_qa(data_path: str, use_existing_trainer: bool = True):
    """
    è®­ç»ƒæ–‡æ¡£é—®ç­”æ¨¡å‹

    Args:
        data_path: è®­ç»ƒæ•°æ®è·¯å¾„
        use_existing_trainer: æ˜¯å¦ä½¿ç”¨ç°æœ‰çš„train_manager
    """
    print("=" * 60)
    print("ğŸ“š æ–‡æ¡£é—®ç­”æ¨¡å‹è®­ç»ƒ")
    print("=" * 60)

    if not os.path.exists(data_path):
        print(f"âŒ è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: {data_path}")
        return None

    if use_existing_trainer:
        # ä½¿ç”¨ç°æœ‰çš„è®­ç»ƒç®¡ç†å™¨
        try:
            from src.training.train_manager import ModelTrainer

            trainer = ModelTrainer()

            print("ğŸ”§ ä½¿ç”¨ç°æœ‰è®­ç»ƒæ¡†æ¶...")

            # è®­ç»ƒé…ç½®ï¼ˆé’ˆå¯¹æ–‡æ¡£QAä¼˜åŒ–ï¼‰
            config = {
                "epochs": 4,  # æ–‡æ¡£éœ€è¦æ›´å¤šè½®æ¬¡
                "batch_size": 2,
                "learning_rate": 3e-5,
                "max_length": 768,  # æ–‡æ¡£éœ€è¦æ›´é•¿ä¸Šä¸‹æ–‡
            }

            # å¼€å§‹è®­ç»ƒ
            model_path = trainer.train_full_model(
                data_path=data_path,
                config=config
            )

            if model_path:
                print(f"\nğŸ‰ æ–‡æ¡£QAè®­ç»ƒå®Œæˆï¼")
                print(f"ğŸ“ æ¨¡å‹: {model_path}")

                # æµ‹è¯•ä¸€ä¸‹
                test_questions = [
                    "è¯·æ€»ç»“æ–‡æ¡£å†…å®¹",
                    "æ–‡æ¡£ä¸­çš„å…³é”®ä¿¡æ¯æ˜¯ä»€ä¹ˆï¼Ÿ",
                    "æ ¹æ®æ–‡æ¡£å›ç­”å…·ä½“é—®é¢˜"
                ]

                print("\nğŸ§ª æµ‹è¯•æ–‡æ¡£é—®ç­”:")
                for q in test_questions:
                    print(f"  Q: {q}")
                    print(f"  A: [è®­ç»ƒåæ¨¡å‹ä¼šåŸºäºæ–‡æ¡£å›ç­”]")

                return model_path

        except ImportError as e:
            print(f"âš ï¸  æ— æ³•å¯¼å…¥ç°æœ‰è®­ç»ƒå™¨: {e}")
            print("ğŸ’¡ å°†ä½¿ç”¨ç®€åŒ–è®­ç»ƒ...")
            use_existing_trainer = False

    if not use_existing_trainer:
        # ç®€åŒ–è®­ç»ƒ
        print("ğŸ”§ ä½¿ç”¨ç®€åŒ–è®­ç»ƒ...")
        # è¿™é‡Œå¯ä»¥æ·»åŠ ç®€åŒ–è®­ç»ƒé€»è¾‘
        print("ğŸ’¡ å»ºè®®å…ˆä½¿ç”¨ç°æœ‰è®­ç»ƒç³»ç»Ÿ")
        return None


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description="æ–‡æ¡£QAè®­ç»ƒ")
    parser.add_argument("--data", type=str, required=True,
                        help="è®­ç»ƒæ•°æ®è·¯å¾„")
    parser.add_argument("--output", type=str,
                        default="./models/document_qa",
                        help="è¾“å‡ºç›®å½•")

    args = parser.parse_args()

    # è®­ç»ƒ
    model_path = train_document_qa(args.data)

    if model_path:
        print(f"\nâœ… è®­ç»ƒå®Œæˆï¼")
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")

        # ä¿å­˜é…ç½®ä¿¡æ¯
        info_file = Path(model_path) / "document_qa_info.json"
        import json
        info = {
            "model_type": "document_qa",
            "training_data": args.data,
            "training_time": "auto_generated",
            "usage": "ä¸“ç”¨äºæ–‡æ¡£é—®ç­”çš„å¾®è°ƒæ¨¡å‹"
        }

        with open(info_file, 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“‹ é…ç½®ä¿¡æ¯: {info_file}")


if __name__ == "__main__":
    main()